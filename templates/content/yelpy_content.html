<div class="banner">
    <div class="banner-image">
        <img src="images/folio-imgs/ARTS/banner.png" alt="ARTS Banner" title="ARTS"/>
    </div>
    <div class="banner-text light-text">
        <div class="banner-title">Auto Rapid Transit System</div>
        <div class="banner-tagline"></div>
    </div>
</div>

<div class="project-content">
    <div id="section-1">
        <div class="left">
            <div class="c01" id="the-problem">
                <h4>The Problem</h4>
                <p>Yelp’s current method of presenting reviews and ratings to the users is seemingly tedious and ineffective. Yelp is looking to invest in machine learning and Conversational UI to boost its business margin while providing their mobile user base a good experience in finding their choice of food.</p>
            </div>

            <div class="c02" id="approach">
                <h4>Approach</h4>
                <p>User interviews, affinity diagramming, paper prototyping and usability testing.</p>
            </div>

            <div class="c04" id="my-role">
                <h4>My Role</h4>
                <p>I was the team facilitator. I moderated the workflow of the team and supervised the design process as a whole.
                   Every team member shared an equal amount of work during every stage of the design process.</p>
            </div>
        </div>


        <div class="right">
            <div class="c03" id="the-team">
                <h4>The Team</h4>
                <ul>
                    <li>Pavithra Ramamurthy</li>
                    <li>Sean Smith</li>
                    <li>Nicole Annicetti</li>
                    <li>Vikas Jangam</li>
                </ul>
            </div>


        </div>
    </div>

    <div id="section-2">
        <h3>Solution</h3>
        <p>
            <bigWord>Yelpy, the food expert</bigWord> is a conversation UI bot that provides food choices to its users based on Yelp’s reviews and ratings. It also leverages machine learning capabilities to study user behaviour and provide personalised recommendations. In this design Yelpy is integrated into BTownMenus, a local food delivery service application based in the college town of Bloomington, Indiana. </p>


<h4>The beginning...</h4>
<p>
  The design prompt asked my team to explore alternatives to Yelp’s current method of providing ratings and reviews using conversational UI.  Our goal would be to improve the experience of the user when they’re looking for something to eat on BTownMenus.com.</p>

<p>
  BTownMenus is a popularly used local delivery service in Bloominton, Indiana that links restaurants which particularly appeal to college students and late-night purchases and delivery.
</p>

        <h4>Whom we spoke to...</h4>

        <p>We began by trying to understand how the users currently experienced BTownMenus and whether they found yelp’s review feature on BtownMenus application to be helpful.</p>
        <p>
          Through our initial research we garnered that Indiana University’s graduate and undergraduate students made up a huge portion of BTownMenu’s <bigWord>primary users.</bigWord> We recorded elaborate interviews about their experience in using BTownMenus and Yelp reviews. Using a casual conversational approach we questioned them on their food choices, how much time they generally spent while ordering food, what motivated them to make their food choices, whether they felt appeal in trying new kinds of food and if so then on what basis they made these choices. Our goal was to understand if they ever utilized Yelp reviews, and when they found the need to use them.
        </p>
        <p>The inputs we acquired from the different interviews was immense and comprehensive. In order to make sense of all the data we had, we created detailed mind maps and visually represented them. This helped us view clear patterns of use cases within our research.
      </p>
      <img src="images/folio-imgs/yelpy/mindmap.png" title="mindmap" class="full-width" alt="Image of our Mind Mapping" />
      <div class="image-sub">Mind Mapping of our Research Data</div>

          <p>
            Based on our mind map we drew several <bigWord>insights</bigWord> on what the users required and how to help them utilise Yelp’s features better.
          </p>
          <ul class="bullets">
            <li>Most of the users did not use Yelp reviews because they found Yelp tedious to use, or were not aware of its presence on the site.</li>
            <li>Users would be more likely to trust suggestions from other customers over the restaurant or business’ suggestions. Some users were skeptical about restaurant recommendations thinking they had some sort of business motive. </li>
            <li>Users care about quality. Seeing a review will give them a first-person perspective on the food experience of a restaurant.</li>
            <li>Current format of Yelp’s reviews on BTownMenus is inconspicuous, without form, and convoluted. Due to this the relevancy has dropped.</li>
          </ul>

<p>Our goal became very clear. We needed to make the Yelp reviews and ratings more relevant through conversational UI, and we would need do it in a transparent way.</p>

<p>Our primary user research provided us with a good insight about our target audience. We gained an understanding about their background, lifestyle, activities and behaviour. Based on our study, we came up with two personas Megan Boyle and Matt Wheeler who represented the full range of our target demographic.</p>

        <h4>What we did...</h4>

        <p>We took to the whiteboard and began by debating on different approaches to solving this issue through conversational UI.</p>

      <p>
        We came up with ‘Yelpy’, our food expert who would provide popular reviews through a conversation, while passively studying user behaviour through machine learning and eventually providing better recommendations. He would have to be a non-intrusive bot to avoid overstepping on the user boundaries, while still being able to encourage people to have a conversation. Our main focus was to make sure that Yelpy behaves as an effective tool in helping users find and choose their food better, quicker, and more easily without any limitations.
      </p>

<p>
  The key factors we explored with our design were
</p>
<ul class="bullets">
  <li>The conversation style in which Yelpy would interact with its users.</li>
<li>Where, when and how Yelpy would be integrated into BTownMenus.</li>
</ul>
<p>
  Based on our secondary research on effective incorporation of conversational UI as a tool we designed Yelpy with very specific capabilities.
</p>
<div class="image-grid">
  <div class="cols_66">
        <p>We generated a variety of ideas for the conversation flow and explored the personality traits of our bot. We gave a specific focus to the language style that yelpy would use in order to enable the users to easily identify and connect comfortably with him. We used casual phrases like “Looks like bomb!,” “More pls!,” “What else?,” and emoticons like “bomb” and “smileys” as the mode of communication.</p>

        <p>An important feature that we placed is the intended delay between each of Yelp’s responses. This again ties to the “human touch” aspect of the conversation.</p>

        <p>We limited the number of Yelpy’s suggestions within each conversational phase in order to avoid overwhelming the users and to keep the interface clean.</p>

        <p>Yelpy would only give recommendations from the current restaurant that a user is viewing at a time. For example, when the user is navigating in Arby’s restaurant page, the recommendations popping up will solely belong to the same restaurant. This is to avoid confusion and not surprise the user when the link redirects them to the second recommended restaurant's page.</p>
        </div>
<div class="cols_33">
<img src="images/folio-imgs/yelpy/Btownmenu_integration.jpg" title="BTown Menu Sketch" alt="Image of the interface sketch of Yelpy within BTownMenus app"/>
</div>
</div>

<p>When Yelpy runs out of popular recommendations at a restaurant  for a particular food type then he would suggest popular choices from other restaurants. This would especially provide choices to people with a specific type of diet.</p>

<img src="images/folio-imgs/yelpy/navigate.png" title="Navigate" alt="Image of Yelpy's search case suggestions" />
<div class="image-sub">Yelpy's recommendations</div>

        <p>Yelpy would sense when users add food choices from multiple restaurants to their carts and provides a heads up in order to avoid confusion and frustration among users. We wanted to incorporate this into our design to account for Yelpy’s suggestion capabilities by keeping users aware of their actions.</p>
        
        <img src="images/folio-imgs/yelpy/cart.png" title="Multiple items" alt="Image of Multiple items cart" />
        <div class="image-sub">Yelp's warning message when multiple items are in Cart</div>

          <p>All the conversations that Yelpy has can only be responded with clickable responses. We made this design choice based on the following factors that we validated through user testing and interviews.</p>

<p>
  The <bigWord>key findings</bigWord> we garnered from these interviews were that
<ul class="bullets">
  <li>
    Drivers are constantly multitasking between driving, communicating with dispatch and other drivers, checking for crowding inside the bus, checking for schedule delays and requests for passenger stops. This gets very difficult to manage and increases risk on the road.
  </li>

  <li>
    Bus drivers heavily rely on communicating with dispatch for reroutes and emergency situations. This coordination usually takes time due to the manual nature of the communication process.
  </li>
  <li>
    Because dispatch is often another driver or different people every time, there is no protocol or consistency and drivers generally feel that dispatch is unreliable. Often the bus drivers make decisions on the go or by manually coordinating on the radio.
  </li>
  <li>
    During delays or overcrowding, bus drivers use hand gestures to communicate with people at a stop to convey that they would be picked up by the next bus instead.
  </li>
</ul>
</p>

<p>
  Our interviews and observations gave us enough lead to build our <bigWord>personas</bigWord> representing both our set of users the drivers and the passengers.
</p>

//insert personas//

        <p>Based on our key findings we were able to pull specific insights that helped us conceptualize a possible solution for the main problems that we recognised.</p>

        <p><bigWord>We understood that people need a reliable bus system where they could just travel comfortably from point A to B without having to wait for a long time during all times of the day.</bigWord></p>
<p>
<bigWord>Drivers needed to Safely offload communication tasks while driving.</bigWord>
</p>

        <p>We needed to figure how we could use Mercedez Benz’s autonomous vehicle features to solve for these very particular problem spaces.
</p>

        <p>We began the round robin sketching process again! We had potentially explosive ideas from our exploration before, but now we were focusing on funneling down to the core aspect of solving the problem. At the end of the process we had a concrete idea that all of us wanted to explore and test.</p>

        //StoryBoard//

        <p>During our initial round of testing phase we walked our testers, both passengers and drivers through concept scenarios and specific situations to judge their responses. We also involved the testers in task based interactions using paper prototypes to record the usability of the interface itself.</p>

        <img src="images/folio-imgs/ARTS/wireframe.png" class="full-width" title="ARTS Wireframe" alt="Image of the wireframe of ARTS" />

        <div class="image-sub">Wireframe - ARTS</div>

<h4>What we found…</h4>
        <p>From testing passengers we realised that there was a certain learning curve to the interface. The passengers tended to think that the interface just provided a real time update of when their bus would arrive. They didn’t recognise that the bus was prioritising stops based on user demands till they rode the bus. Nevertheless, they liked the fact that they got realtime updates of the bus arrival times.
</p>

        <p>In our initial design of the driver’s interface, we had a visual map that would indicate route changes and allocated stops. While usability testing our design with our drivers we realised that the map interface showing priority stops along route can be a safety hazard if driver has to take quick looks at it.
</p>
<p>What more, the drivers are already aware and knowledgeable about different bus routes and streets, in which case a visual navigation system may be unnecessary.
</p>

<p>
We <bigWord>Concluded</bigWord> that a voice interface for receiving priority routes instead of a visual interface would be a more viable design modification for bus drivers. We also decided to have a brief animated introduction to the autonomous prioritization system on the passenger’s interface.
</p>


        <p>Based on these modifications we would like to run further high fidelity usability tests on a focused community utilising one or two bus lines while using a Mercedes Benz’s centrally controlled infrastructure to optimise the autonomous prioritisation.

</p>
<p>
  We want to design for current infrastructure and put a better system in place in the coming years. And eventually fluidly transition from some specific autonomous functions (ie automated route-passenger prioritization system) to semi-autonomous aided functions (ie the prior system with autopilot) to fully autonomous (fully self driving incorporating the proposed system).
</p>
<img src="images/folio-imgs/ARTS/SCOPE.png" class="full-width" title="Scope" alt="Scope of the design" />

<h4>The Team</h4>
        <img src="images/folio-imgs/ARTS/teampic.jpg" class="full-width" title="Team Picture" alt="A Picture of the team." />
        <div class="image-sub">FROM LEFT: PHILIP BEGEL, PAVITHRA RAMAMURTHY(ME), Sanjana Mathur & Peggy Lu</div>

        <h4>What I Learnt</h4>
        <ul class="bullets">
            <li>User experience designing is never a linear process and the users can help you validate your concept every step of the way
</li>
            <li>Ask questions, lots and lots of questions on every aspect of the problem space. Record these questions and work with your team to answer all of them throughout the design process. Then ask more questions.
</li>
<li>Design iteratively and be ready to chuck your ideas and go back to phase one if necessary.
</li>
        </ul>
    </div>
</div>
